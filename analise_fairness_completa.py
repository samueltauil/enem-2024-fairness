"""
An√°lise COMPLETA de Fairness - ENEM 2024
=========================================

Implementa√ß√£o otimizada usando:
- 100% dos dados (sem amostragem)
- Todas as m√©tricas Fairlearn dispon√≠veis
- Visualiza√ß√µes interativas e est√°ticas
- Pipeline de processamento eficiente

Autor: An√°lise Otimizada
Data: 2025-11-05
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Fairlearn imports
from fairlearn.metrics import (
    MetricFrame,
    demographic_parity_difference,
    demographic_parity_ratio,
    selection_rate,
    count
)

# Sklearn imports
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Configura√ß√£o
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)

# Criar estrutura de pastas
PATHS = {
    'dados': Path('dados/DADOS'),
    'resultados': Path('resultados'),
    'graficos': Path('resultados/graficos'),
    'tabelas': Path('resultados/tabelas'),
    'reports': Path('resultados/reports')
}

for path in PATHS.values():
    path.mkdir(parents=True, exist_ok=True)

start_time = datetime.now()

print("="*100)
print("üìä AN√ÅLISE COMPLETA DE FAIRNESS - ENEM 2024")
print("="*100)
print(f"In√≠cio: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
print("\nüéØ CONFIGURA√á√ÉO:")
print("   ‚úÖ Usando 100% dos dados dispon√≠veis")
print("   ‚úÖ Processamento otimizado com tipos eficientes")
print("   ‚úÖ Todas as m√©tricas Fairlearn implementadas")
print("   ‚úÖ Visualiza√ß√µes completas (10 gr√°ficos)")
print("="*100)

# ============================================================================
# PARTE 1: CARREGAMENTO OTIMIZADO
# ============================================================================

print("\nüìÅ [1/8] Carregando dados com otimiza√ß√£o de mem√≥ria...")
print("-" * 100)

try:
    load_start = datetime.now()
    
    # Carregar sem dtypes expl√≠citos (para lidar com NAs)
    participantes = pd.read_csv(
        PATHS['dados'] / 'PARTICIPANTES_2024.csv',
        sep=';',
        encoding='latin1',
        low_memory=False
    )
    print(f"‚úÖ Participantes: {len(participantes):,} registros")
    
    resultados = pd.read_csv(
        PATHS['dados'] / 'RESULTADOS_2024.csv',
        sep=';',
        encoding='latin1',
        low_memory=False
    )
    print(f"‚úÖ Resultados: {len(resultados):,} registros")
    
    # Otimizar tipos ap√≥s carregamento
    print("‚öôÔ∏è  Otimizando tipos de dados...")
    for col in ['TP_SEXO', 'SG_UF_PROVA']:
        if col in participantes.columns:
            participantes[col] = participantes[col].astype('category')
    for col in ['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO']:
        if col in resultados.columns:
            resultados[col] = resultados[col].astype('float32')
    
    load_time = (datetime.now() - load_start).total_seconds()
    print(f"‚è±Ô∏è  Tempo de carregamento: {load_time:.2f}s")
    
except FileNotFoundError as e:
    print(f"‚ùå Erro: {e}")
    print("   Verifique se os arquivos est√£o em dados/DADOS/")
    exit(1)

# Valida√ß√£o
assert len(participantes) == len(resultados), "Tamanhos diferentes!"

# ============================================================================
# PARTE 2: UNI√ÉO E PREPARA√á√ÉO EFICIENTE
# ============================================================================

print("\nüîó [2/8] Unindo datasets e criando vari√°veis...")
print("-" * 100)

# Uni√£o por √≠ndice (m√©todo validado pela documenta√ß√£o INEP)
dados = pd.concat([
    participantes.reset_index(drop=True),
    resultados.reset_index(drop=True)
], axis=1)

# Remover colunas duplicadas
dados = dados.loc[:, ~dados.columns.duplicated()]
print(f"‚úÖ Dataset unificado: {len(dados):,} registros √ó {len(dados.columns)} colunas")

# Filtrar participantes completos (SEM AMOSTRAGEM!)
mask_completo = (
    (dados['TP_PRESENCA_CN'] == 1) &
    (dados['TP_PRESENCA_CH'] == 1) &
    (dados['TP_PRESENCA_LC'] == 1) &
    (dados['TP_PRESENCA_MT'] == 1) &
    (dados['TP_STATUS_REDACAO'] == 1) &
    (dados['IN_TREINEIRO'] == 0)
)

dados_completos = dados[mask_completo].copy()
print(f"‚úÖ Participantes completos: {len(dados_completos):,} ({len(dados_completos)/len(dados)*100:.2f}%)")

# Liberar mem√≥ria
del dados, participantes, resultados

# Criar vari√°veis de outcome
print("\nüìä Criando vari√°veis de an√°lise...")
dados_completos['NOTA_MEDIA'] = dados_completos[[
    'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO'
]].mean(axis=1)

dados_completos['NOTA_STEM'] = dados_completos[['NU_NOTA_CN', 'NU_NOTA_MT']].mean(axis=1)
dados_completos['NOTA_HUMAN'] = dados_completos[['NU_NOTA_CH', 'NU_NOTA_LC']].mean(axis=1)
dados_completos['NOTA_OBJETIVA'] = dados_completos[['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT']].mean(axis=1)

# Vari√°veis bin√°rias para classifica√ß√£o
dados_completos['APROVADO_600'] = (dados_completos['NOTA_MEDIA'] >= 600).astype(np.uint8)
dados_completos['APROVADO_700'] = (dados_completos['NOTA_MEDIA'] >= 700).astype(np.uint8)
dados_completos['ALTA_PERF'] = (dados_completos['NOTA_MEDIA'] >= 750).astype(np.uint8)

# Quartis
dados_completos['QUARTIL'] = pd.qcut(
    dados_completos['NOTA_MEDIA'],
    q=4,
    labels=['Q1', 'Q2', 'Q3', 'Q4']
)

# Decis
dados_completos['DECIL'] = pd.qcut(
    dados_completos['NOTA_MEDIA'],
    q=10,
    labels=[f'D{i}' for i in range(1, 11)]
)

print("‚úÖ Vari√°veis criadas:")
print(f"   - NOTA_MEDIA: Œº={dados_completos['NOTA_MEDIA'].mean():.2f}, œÉ={dados_completos['NOTA_MEDIA'].std():.2f}")
print(f"   - APROVADO_600: {dados_completos['APROVADO_600'].sum():,} ({dados_completos['APROVADO_600'].mean()*100:.2f}%)")
print(f"   - APROVADO_700: {dados_completos['APROVADO_700'].sum():,} ({dados_completos['APROVADO_700'].mean()*100:.2f}%)")
print(f"   - ALTA_PERF: {dados_completos['ALTA_PERF'].sum():,} ({dados_completos['ALTA_PERF'].mean()*100:.2f}%)")

# ============================================================================
# PARTE 3: PREPARAR ATRIBUTOS SENS√çVEIS
# ============================================================================

print("\nüéØ [3/8] Preparando atributos sens√≠veis...")
print("-" * 100)

# Mapear c√≥digos
mapa_raca = {
    0: 'N√£o declarado', 1: 'Branca', 2: 'Preta', 3: 'Parda',
    4: 'Amarela', 5: 'Ind√≠gena', 6: 'Sem informa√ß√£o'
}

mapa_sexo = {'M': 'Masculino', 'F': 'Feminino'}

mapa_regiao = {
    11: 'Norte', 12: 'Norte', 13: 'Norte', 14: 'Norte', 15: 'Norte', 16: 'Norte', 17: 'Norte',
    21: 'Nordeste', 22: 'Nordeste', 23: 'Nordeste', 24: 'Nordeste', 25: 'Nordeste',
    26: 'Nordeste', 27: 'Nordeste', 28: 'Nordeste', 29: 'Nordeste',
    31: 'Sudeste', 32: 'Sudeste', 33: 'Sudeste', 35: 'Sudeste',
    41: 'Sul', 42: 'Sul', 43: 'Sul',
    50: 'Centro-Oeste', 51: 'Centro-Oeste', 52: 'Centro-Oeste', 53: 'Centro-Oeste'
}

dados_completos['RACA'] = dados_completos['TP_COR_RACA'].map(mapa_raca).astype('category')
dados_completos['SEXO'] = dados_completos['TP_SEXO'].map(mapa_sexo).astype('category')
dados_completos['REGIAO'] = dados_completos['CO_UF_PROVA'].map(mapa_regiao).astype('category')

# Filtrar apenas com atributos v√°lidos
dados_analise = dados_completos[
    (dados_completos['TP_COR_RACA'].isin([1, 2, 3, 4, 5])) &
    (dados_completos['SEXO'].notna()) &
    (dados_completos['REGIAO'].notna())
].copy()

print(f"‚úÖ Dataset para an√°lise: {len(dados_analise):,} registros")
print("\nüìä Distribui√ß√µes:")
print(f"\nRa√ßa/Cor:\n{dados_analise['RACA'].value_counts().to_string()}")
print(f"\nSexo:\n{dados_analise['SEXO'].value_counts().to_string()}")
print(f"\nRegi√£o:\n{dados_analise['REGIAO'].value_counts().to_string()}")

# ============================================================================
# PARTE 4: M√âTRICAS PERSONALIZADAS
# ============================================================================

print("\n‚öôÔ∏è  [4/8] Definindo m√©tricas personalizadas...")
print("-" * 100)

def media(y_true, y_pred):
    """M√©dia das notas"""
    return np.mean(y_pred)

def mediana(y_true, y_pred):
    """Mediana das notas"""
    return np.median(y_pred)

def desvio(y_true, y_pred):
    """Desvio padr√£o"""
    return np.std(y_pred)

def q1(y_true, y_pred):
    """Primeiro quartil"""
    return np.percentile(y_pred, 25)

def q3(y_true, y_pred):
    """Terceiro quartil"""
    return np.percentile(y_pred, 75)

def p10(y_true, y_pred):
    """10¬∫ percentil"""
    return np.percentile(y_pred, 10)

def p90(y_true, y_pred):
    """90¬∫ percentil"""
    return np.percentile(y_pred, 90)

def iqr(y_true, y_pred):
    """Intervalo interquartil"""
    return np.percentile(y_pred, 75) - np.percentile(y_pred, 25)

def cv(y_true, y_pred):
    """Coeficiente de varia√ß√£o"""
    return np.std(y_pred) / np.mean(y_pred) if np.mean(y_pred) > 0 else 0

print("‚úÖ 9 m√©tricas personalizadas definidas")

# ============================================================================
# PARTE 5: AN√ÅLISES FAIRLEARN COMPLETAS
# ============================================================================

print("\n‚öñÔ∏è  [5/8] Executando an√°lises Fairlearn completas...")
print("-" * 100)

metricas_regressao = {
    'm√©dia': media,
    'mediana': mediana,
    'desvio': desvio,
    'Q1': q1,
    'Q3': q3,
    'P10': p10,
    'P90': p90,
    'IQR': iqr,
    'CV': cv,
    'contagem': count
}

metricas_classificacao = {
    'taxa_selecao': selection_rate,
    'contagem': count
}

# --- AN√ÅLISE 1: POR RA√áA ---
print("\n1Ô∏è‚É£  An√°lise por Ra√ßa/Cor")
print("-" * 80)

mf_raca = MetricFrame(
    metrics=metricas_regressao,
    y_true=dados_analise['NOTA_MEDIA'],
    y_pred=dados_analise['NOTA_MEDIA'],
    sensitive_features=dados_analise['RACA']
)

print("\nüìä Estat√≠sticas por Ra√ßa:")
print(mf_raca.by_group.round(2).to_string())

print("\n‚ö†Ô∏è  Disparidades (max - min):")
disp_raca = mf_raca.difference(method='between_groups')
for metrica, valor in disp_raca.items():
    if metrica != 'contagem':
        print(f"   {metrica}: {valor:.2f} pontos")

print("\nüìä Raz√µes (min / max):")
razoes_raca = mf_raca.ratio(method='between_groups')
for metrica, valor in razoes_raca.items():
    if metrica != 'contagem':
        status = "‚úÖ" if valor >= 0.80 else "‚ùå"
        print(f"   {status} {metrica}: {valor:.4f}")

# Aprova√ß√£o por ra√ßa
mf_aprov_raca = MetricFrame(
    metrics=metricas_classificacao,
    y_true=dados_analise['APROVADO_600'],
    y_pred=dados_analise['APROVADO_600'],
    sensitive_features=dados_analise['RACA']
)

print("\n‚úÖ Taxas de Aprova√ß√£o (‚â•600):")
print((mf_aprov_raca.by_group * 100).round(2).to_string())

dp_diff = demographic_parity_difference(
    dados_analise['APROVADO_600'],
    dados_analise['APROVADO_600'],
    sensitive_features=dados_analise['RACA']
)
dp_ratio = demographic_parity_ratio(
    dados_analise['APROVADO_600'],
    dados_analise['APROVADO_600'],
    sensitive_features=dados_analise['RACA']
)

print(f"\n‚öñÔ∏è  Demographic Parity:")
print(f"   Diferen√ßa: {dp_diff:.4f} ({dp_diff*100:.2f} pp)")
print(f"   Raz√£o: {dp_ratio:.4f} {'‚úÖ' if dp_ratio >= 0.80 else '‚ùå'}")

# --- AN√ÅLISE 2: POR SEXO ---
print("\n2Ô∏è‚É£  An√°lise por Sexo")
print("-" * 80)

mf_sexo = MetricFrame(
    metrics=metricas_regressao,
    y_true=dados_analise['NOTA_MEDIA'],
    y_pred=dados_analise['NOTA_MEDIA'],
    sensitive_features=dados_analise['SEXO']
)

print("\nüìä Estat√≠sticas por Sexo:")
print(mf_sexo.by_group.round(2).to_string())

print("\n‚ö†Ô∏è  Disparidades:")
disp_sexo = mf_sexo.difference(method='between_groups')
for metrica, valor in disp_sexo.items():
    if metrica != 'contagem':
        print(f"   {metrica}: {valor:.2f} pontos")

# STEM vs Humanidades por sexo
mf_stem_sexo = MetricFrame(
    metrics={'m√©dia': media},
    y_true=dados_analise['NOTA_STEM'],
    y_pred=dados_analise['NOTA_STEM'],
    sensitive_features=dados_analise['SEXO']
)

mf_human_sexo = MetricFrame(
    metrics={'m√©dia': media},
    y_true=dados_analise['NOTA_HUMAN'],
    y_pred=dados_analise['NOTA_HUMAN'],
    sensitive_features=dados_analise['SEXO']
)

print("\nüî¨ STEM vs Humanidades:")
print(f"STEM:\n{mf_stem_sexo.by_group.round(2).to_string()}")
print(f"\nHumanidades:\n{mf_human_sexo.by_group.round(2).to_string()}")

# --- AN√ÅLISE 3: POR REGI√ÉO ---
print("\n3Ô∏è‚É£  An√°lise por Regi√£o")
print("-" * 80)

mf_regiao = MetricFrame(
    metrics=metricas_regressao,
    y_true=dados_analise['NOTA_MEDIA'],
    y_pred=dados_analise['NOTA_MEDIA'],
    sensitive_features=dados_analise['REGIAO']
)

print("\nüìä Estat√≠sticas por Regi√£o:")
print(mf_regiao.by_group.round(2).to_string())

print("\n‚ö†Ô∏è  Disparidades:")
disp_regiao = mf_regiao.difference(method='between_groups')
for metrica, valor in disp_regiao.items():
    if metrica != 'contagem':
        print(f"   {metrica}: {valor:.2f} pontos")

# --- AN√ÅLISE 4: INTERSECCIONALIDADE (Ra√ßa √ó Sexo) ---
print("\n4Ô∏è‚É£  An√°lise Interseccional (Ra√ßa √ó Sexo)")
print("-" * 80)

# Criar combina√ß√£o
dados_analise['RACA_SEXO'] = dados_analise['RACA'].astype(str) + ' - ' + dados_analise['SEXO'].astype(str)

mf_intersec = MetricFrame(
    metrics={'m√©dia': media, 'mediana': mediana, 'contagem': count},
    y_true=dados_analise['NOTA_MEDIA'],
    y_pred=dados_analise['NOTA_MEDIA'],
    sensitive_features=dados_analise['RACA_SEXO']
)

print("\nüìä Top 10 grupos (m√©dia):")
top10 = mf_intersec.by_group.sort_values('m√©dia', ascending=False).head(10)
print(top10.round(2).to_string())

print("\nüìä Bottom 10 grupos (m√©dia):")
bottom10 = mf_intersec.by_group.sort_values('m√©dia', ascending=True).head(10)
print(bottom10.round(2).to_string())

gap_intersec = top10['m√©dia'].iloc[0] - bottom10['m√©dia'].iloc[0]
print(f"\nüìâ Gap m√°ximo: {gap_intersec:.2f} pontos")

# --- AN√ÅLISE 5: INTERSECCIONALIDADE (Ra√ßa √ó Regi√£o) ---
print("\n5Ô∏è‚É£  An√°lise Interseccional (Ra√ßa √ó Regi√£o)")
print("-" * 80)

# Limitar a ra√ßas principais
dados_principais = dados_analise[dados_analise['TP_COR_RACA'].isin([1,2,3])].copy()
dados_principais['RACA_REGIAO'] = dados_principais['RACA'].astype(str) + ' - ' + dados_principais['REGIAO'].astype(str)

mf_raca_regiao = MetricFrame(
    metrics={'m√©dia': media, 'contagem': count},
    y_true=dados_principais['NOTA_MEDIA'],
    y_pred=dados_principais['NOTA_MEDIA'],
    sensitive_features=dados_principais['RACA_REGIAO']
)

print("\nüìä Top 10 combina√ß√µes Ra√ßa √ó Regi√£o:")
top10_rr = mf_raca_regiao.by_group.sort_values('m√©dia', ascending=False).head(10)
print(top10_rr.round(2).to_string())

print("\nüìä Bottom 10 combina√ß√µes Ra√ßa √ó Regi√£o:")
bottom10_rr = mf_raca_regiao.by_group.sort_values('m√©dia', ascending=True).head(10)
print(bottom10_rr.round(2).to_string())

# ============================================================================
# PARTE 6: VISUALIZA√á√ïES COMPLETAS
# ============================================================================

print("\nüìä [6/8] Gerando visualiza√ß√µes completas...")
print("-" * 100)

# --- GR√ÅFICO 1: Dashboard de Fairness por Ra√ßa ---
fig, axes = plt.subplots(2, 3, figsize=(20, 12))
fig.suptitle('Dashboard de Fairness por Ra√ßa/Cor - ENEM 2024', fontsize=16, fontweight='bold')

# 1.1: Boxplot
dados_box = dados_analise[dados_analise['TP_COR_RACA'].isin([1,2,3])]
ordem = dados_box.groupby('RACA')['NOTA_MEDIA'].median().sort_values(ascending=False).index
sns.boxplot(data=dados_box, x='RACA', y='NOTA_MEDIA', order=ordem, ax=axes[0,0])
axes[0,0].set_title('Distribui√ß√£o de Notas')
axes[0,0].axhline(y=600, color='r', linestyle='--', alpha=0.5)
axes[0,0].tick_params(axis='x', rotation=45)

# 1.2: Barplot m√©dias
medias = mf_raca.by_group['m√©dia'].sort_values(ascending=False)
medias.plot(kind='bar', ax=axes[0,1], color='steelblue', edgecolor='black')
axes[0,1].set_title('Nota M√©dia por Ra√ßa')
axes[0,1].axhline(y=600, color='r', linestyle='--', alpha=0.5)
axes[0,1].tick_params(axis='x', rotation=45)

# 1.3: Taxa de aprova√ß√£o
taxas_aprov = mf_aprov_raca.by_group['taxa_selecao'] * 100
taxas_aprov = taxas_aprov.sort_values(ascending=False)
taxas_aprov.plot(kind='bar', ax=axes[0,2], color='forestgreen', edgecolor='black')
axes[0,2].set_title('Taxa de Aprova√ß√£o (‚â•600)')
axes[0,2].set_ylabel('Percentual (%)')
axes[0,2].tick_params(axis='x', rotation=45)

# 1.4: Violin plot
sns.violinplot(data=dados_box, x='RACA', y='NOTA_MEDIA', order=ordem, ax=axes[1,0], inner='quartile')
axes[1,0].set_title('Distribui√ß√£o Completa (Violin)')
axes[1,0].axhline(y=600, color='r', linestyle='--', alpha=0.5)
axes[1,0].tick_params(axis='x', rotation=45)

# 1.5: Disparidades (diferen√ßas)
disp_plot = pd.Series({k: v for k, v in disp_raca.items() if k != 'contagem'})
disp_plot.plot(kind='barh', ax=axes[1,1], color='coral')
axes[1,1].set_title('Disparidades (max - min)')
axes[1,1].set_xlabel('Pontos')

# 1.6: Raz√µes (80% rule)
razoes_plot = pd.Series({k: v for k, v in razoes_raca.items() if k != 'contagem'})
razoes_plot.plot(kind='barh', ax=axes[1,2], color='skyblue')
axes[1,2].axvline(x=0.80, color='r', linestyle='--', label='80% Rule')
axes[1,2].set_title('Raz√µes (min / max)')
axes[1,2].set_xlabel('Raz√£o')
axes[1,2].legend()

plt.tight_layout()
plt.savefig(PATHS['graficos'] / '01_dashboard_raca.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 01_dashboard_raca.png")
plt.close()

# --- GR√ÅFICO 2: Dashboard por Sexo ---
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('Dashboard de Fairness por Sexo - ENEM 2024', fontsize=16, fontweight='bold')

# 2.1: Boxplot
sns.boxplot(data=dados_analise, x='SEXO', y='NOTA_MEDIA', ax=axes[0,0])
axes[0,0].set_title('Distribui√ß√£o de Notas')
axes[0,0].axhline(y=600, color='r', linestyle='--', alpha=0.5)

# 2.2: STEM vs Humanidades
dados_stem_human = pd.DataFrame({
    'STEM': mf_stem_sexo.by_group['m√©dia'],
    'Humanidades': mf_human_sexo.by_group['m√©dia']
})
dados_stem_human.plot(kind='bar', ax=axes[0,1], edgecolor='black')
axes[0,1].set_title('STEM vs Humanidades por Sexo')
axes[0,1].tick_params(axis='x', rotation=0)
axes[0,1].legend()

# 2.3: Distribui√ß√£o por provas
provas_sexo = pd.DataFrame({
    'CN': dados_analise.groupby('SEXO')['NU_NOTA_CN'].mean(),
    'CH': dados_analise.groupby('SEXO')['NU_NOTA_CH'].mean(),
    'LC': dados_analise.groupby('SEXO')['NU_NOTA_LC'].mean(),
    'MT': dados_analise.groupby('SEXO')['NU_NOTA_MT'].mean(),
    'Reda√ß√£o': dados_analise.groupby('SEXO')['NU_NOTA_REDACAO'].mean()
})
provas_sexo.plot(kind='bar', ax=axes[1,0], edgecolor='black')
axes[1,0].set_title('M√©dia por Prova e Sexo')
axes[1,0].tick_params(axis='x', rotation=0)
axes[1,0].legend(loc='best')

# 2.4: Disparidades
disp_sexo_plot = pd.Series({k: v for k, v in disp_sexo.items() if k != 'contagem'})
disp_sexo_plot.plot(kind='barh', ax=axes[1,1], color='salmon')
axes[1,1].set_title('Disparidades entre Sexos')
axes[1,1].set_xlabel('Pontos')

plt.tight_layout()
plt.savefig(PATHS['graficos'] / '02_dashboard_sexo.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 02_dashboard_sexo.png")
plt.close()

# --- GR√ÅFICO 3: Dashboard por Regi√£o ---
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('Dashboard de Fairness por Regi√£o - ENEM 2024', fontsize=16, fontweight='bold')

# 3.1: Boxplot
ordem_reg = dados_analise.groupby('REGIAO')['NOTA_MEDIA'].median().sort_values(ascending=False).index
sns.boxplot(data=dados_analise, x='REGIAO', y='NOTA_MEDIA', order=ordem_reg, ax=axes[0,0])
axes[0,0].set_title('Distribui√ß√£o de Notas')
axes[0,0].axhline(y=600, color='r', linestyle='--', alpha=0.5)
axes[0,0].tick_params(axis='x', rotation=45)

# 3.2: M√©dias
medias_reg = mf_regiao.by_group['m√©dia'].sort_values(ascending=False)
medias_reg.plot(kind='bar', ax=axes[0,1], color='teal', edgecolor='black')
axes[0,1].set_title('Nota M√©dia por Regi√£o')
axes[0,1].axhline(y=600, color='r', linestyle='--', alpha=0.5)
axes[0,1].tick_params(axis='x', rotation=45)

# 3.3: Taxa de aprova√ß√£o por regi√£o
mf_aprov_reg = MetricFrame(
    metrics={'taxa': selection_rate},
    y_true=dados_analise['APROVADO_600'],
    y_pred=dados_analise['APROVADO_600'],
    sensitive_features=dados_analise['REGIAO']
)
taxas_reg = (mf_aprov_reg.by_group['taxa'] * 100).sort_values(ascending=False)
taxas_reg.plot(kind='bar', ax=axes[1,0], color='gold', edgecolor='black')
axes[1,0].set_title('Taxa de Aprova√ß√£o por Regi√£o')
axes[1,0].set_ylabel('Percentual (%)')
axes[1,0].tick_params(axis='x', rotation=45)

# 3.4: Disparidades
disp_reg_plot = pd.Series({k: v for k, v in disp_regiao.items() if k != 'contagem'})
disp_reg_plot.plot(kind='barh', ax=axes[1,1], color='orchid')
axes[1,1].set_title('Disparidades entre Regi√µes')
axes[1,1].set_xlabel('Pontos')

plt.tight_layout()
plt.savefig(PATHS['graficos'] / '03_dashboard_regiao.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 03_dashboard_regiao.png")
plt.close()

# --- GR√ÅFICO 4: Heatmap Interseccionalidade (Ra√ßa √ó Sexo) ---
plt.figure(figsize=(14, 10))
pivot = dados_analise.pivot_table(
    values='NOTA_MEDIA',
    index='RACA',
    columns='SEXO',
    aggfunc='mean'
)
sns.heatmap(pivot, annot=True, fmt='.1f', cmap='RdYlGn', center=600, cbar_kws={'label': 'Nota M√©dia'})
plt.title('Heatmap Interseccional: Ra√ßa √ó Sexo (ENEM 2024)', fontsize=14, fontweight='bold')
plt.ylabel('Ra√ßa/Cor')
plt.xlabel('Sexo')
plt.tight_layout()
plt.savefig(PATHS['graficos'] / '04_heatmap_raca_sexo.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 04_heatmap_raca_sexo.png")
plt.close()

# --- GR√ÅFICO 5: Heatmap Interseccionalidade (Ra√ßa √ó Regi√£o) ---
plt.figure(figsize=(14, 10))
pivot_rr = dados_principais.pivot_table(
    values='NOTA_MEDIA',
    index='RACA',
    columns='REGIAO',
    aggfunc='mean'
)
sns.heatmap(pivot_rr, annot=True, fmt='.1f', cmap='RdYlGn', center=600, cbar_kws={'label': 'Nota M√©dia'})
plt.title('Heatmap Interseccional: Ra√ßa √ó Regi√£o (ENEM 2024)', fontsize=14, fontweight='bold')
plt.ylabel('Ra√ßa/Cor')
plt.xlabel('Regi√£o')
plt.tight_layout()
plt.savefig(PATHS['graficos'] / '05_heatmap_raca_regiao.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 05_heatmap_raca_regiao.png")
plt.close()

# --- GR√ÅFICO 6: Distribui√ß√£o por Quartis (Ra√ßa) ---
plt.figure(figsize=(14, 8))
quartis_raca = pd.crosstab(
    dados_analise['QUARTIL'],
    dados_analise['RACA'],
    normalize='index'
) * 100
quartis_raca.plot(kind='bar', stacked=True, edgecolor='black', figsize=(14, 8))
plt.title('Distribui√ß√£o Racial por Quartis de Desempenho', fontsize=14, fontweight='bold')
plt.xlabel('Quartil')
plt.ylabel('Percentual (%)')
plt.legend(title='Ra√ßa/Cor', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=0)
plt.tight_layout()
plt.savefig(PATHS['graficos'] / '06_quartis_raca.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 06_quartis_raca.png")
plt.close()

# --- GR√ÅFICO 7: Distribui√ß√£o por Decis (Ra√ßa) ---
plt.figure(figsize=(16, 8))
decis_raca = pd.crosstab(
    dados_analise['DECIL'],
    dados_analise['RACA'],
    normalize='index'
) * 100
decis_raca.plot(kind='bar', stacked=True, edgecolor='black', figsize=(16, 8))
plt.title('Distribui√ß√£o Racial por Decis de Desempenho', fontsize=14, fontweight='bold')
plt.xlabel('Decil')
plt.ylabel('Percentual (%)')
plt.legend(title='Ra√ßa/Cor', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.xticks(rotation=0)
plt.tight_layout()
plt.savefig(PATHS['graficos'] / '07_decis_raca.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 07_decis_raca.png")
plt.close()

# --- GR√ÅFICO 8: An√°lise de Extremos (Top 10% vs Bottom 10%) ---
fig, axes = plt.subplots(1, 2, figsize=(16, 6))
fig.suptitle('An√°lise de Extremos: Top 10% vs Bottom 10%', fontsize=14, fontweight='bold')

p90_val = dados_analise['NOTA_MEDIA'].quantile(0.90)
p10_val = dados_analise['NOTA_MEDIA'].quantile(0.10)

top10_data = dados_analise[dados_analise['NOTA_MEDIA'] >= p90_val]
bottom10_data = dados_analise[dados_analise['NOTA_MEDIA'] <= p10_val]

dist_top = top10_data['RACA'].value_counts(normalize=True).sort_index() * 100
dist_bottom = bottom10_data['RACA'].value_counts(normalize=True).sort_index() * 100

dist_top.plot(kind='bar', ax=axes[0], color='green', edgecolor='black', alpha=0.7)
axes[0].set_title(f'Top 10% (‚â•{p90_val:.1f} pontos)')
axes[0].set_ylabel('Percentual (%)')
axes[0].tick_params(axis='x', rotation=45)

dist_bottom.plot(kind='bar', ax=axes[1], color='red', edgecolor='black', alpha=0.7)
axes[1].set_title(f'Bottom 10% (‚â§{p10_val:.1f} pontos)')
axes[1].set_ylabel('Percentual (%)')
axes[1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.savefig(PATHS['graficos'] / '08_extremos_raca.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 08_extremos_raca.png")
plt.close()

# --- GR√ÅFICO 9: Scatter Matrix Interseccional ---
from pandas.plotting import scatter_matrix

dados_scatter = dados_analise[['NU_NOTA_CN', 'NU_NOTA_MT', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_REDACAO']].sample(n=min(10000, len(dados_analise)), random_state=42)
fig = scatter_matrix(dados_scatter, figsize=(16, 16), alpha=0.2, diagonal='kde')
plt.suptitle('Scatter Matrix: Correla√ß√µes entre Provas (Amostra)', fontsize=14, fontweight='bold', y=0.995)
plt.savefig(PATHS['graficos'] / '09_scatter_matrix_provas.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 09_scatter_matrix_provas.png")
plt.close()

# --- GR√ÅFICO 10: Correla√ß√£o entre Provas (Heatmap) ---
plt.figure(figsize=(10, 8))
corr = dados_analise[['NU_NOTA_CN', 'NU_NOTA_MT', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_REDACAO']].corr()
sns.heatmap(corr, annot=True, fmt='.3f', cmap='coolwarm', center=0, square=True, linewidths=1)
plt.title('Correla√ß√£o entre Notas das Provas', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig(PATHS['graficos'] / '10_correlacao_provas.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: 10_correlacao_provas.png")
plt.close()

print(f"\n‚úÖ Total: 10 gr√°ficos gerados em {PATHS['graficos']}/")

# ============================================================================
# PARTE 7: EXPORTAR TABELAS
# ============================================================================

print("\nüì§ [7/8] Exportando tabelas de resultados...")
print("-" * 100)

# Tabela 1: Estat√≠sticas por Ra√ßa
mf_raca.by_group.to_csv(PATHS['tabelas'] / 'estatisticas_raca.csv')
print("‚úÖ estatisticas_raca.csv")

# Tabela 2: Estat√≠sticas por Sexo
mf_sexo.by_group.to_csv(PATHS['tabelas'] / 'estatisticas_sexo.csv')
print("‚úÖ estatisticas_sexo.csv")

# Tabela 3: Estat√≠sticas por Regi√£o
mf_regiao.by_group.to_csv(PATHS['tabelas'] / 'estatisticas_regiao.csv')
print("‚úÖ estatisticas_regiao.csv")

# Tabela 4: Interseccionalidade Ra√ßa √ó Sexo
mf_intersec.by_group.to_csv(PATHS['tabelas'] / 'intersec_raca_sexo.csv')
print("‚úÖ intersec_raca_sexo.csv")

# Tabela 5: Interseccionalidade Ra√ßa √ó Regi√£o
mf_raca_regiao.by_group.to_csv(PATHS['tabelas'] / 'intersec_raca_regiao.csv')
print("‚úÖ intersec_raca_regiao.csv")

# Tabela 6: Aprova√ß√£o por Ra√ßa (todos os thresholds)
aprovacao_completa = pd.DataFrame({
    'aprovado_600': dados_analise.groupby('RACA')['APROVADO_600'].mean() * 100,
    'aprovado_700': dados_analise.groupby('RACA')['APROVADO_700'].mean() * 100,
    'alta_perf': dados_analise.groupby('RACA')['ALTA_PERF'].mean() * 100
})
aprovacao_completa.to_csv(PATHS['tabelas'] / 'taxas_aprovacao_raca.csv')
print("‚úÖ taxas_aprovacao_raca.csv")

# Tabela 7: Disparidades resumidas
disparidades_resumo = pd.DataFrame({
    'Ra√ßa': disp_raca,
    'Sexo': disp_sexo,
    'Regi√£o': disp_regiao
})
disparidades_resumo.to_csv(PATHS['tabelas'] / 'resumo_disparidades.csv')
print("‚úÖ resumo_disparidades.csv")

print(f"\n‚úÖ Total: 7 tabelas exportadas em {PATHS['tabelas']}/")

# ============================================================================
# PARTE 8: RELAT√ìRIO FINAL
# ============================================================================

print("\nüìã [8/8] Gerando relat√≥rio final...")
print("-" * 100)

with open(PATHS['reports'] / 'RELATORIO_COMPLETO.md', 'w', encoding='utf-8') as f:
    f.write(f"""# üìä RELAT√ìRIO COMPLETO DE FAIRNESS - ENEM 2024

**Data de Gera√ß√£o**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## üìà RESUMO EXECUTIVO

### Dados Analisados
- **Total de participantes completos**: {len(dados_completos):,}
- **Registros na an√°lise**: {len(dados_analise):,} (100% dos dados - sem amostragem)
- **Crit√©rio**: Presen√ßa em todas as provas + reda√ß√£o corrigida + n√£o-treineiro

### Estat√≠sticas Gerais
- **Nota M√©dia Geral**: {dados_analise['NOTA_MEDIA'].mean():.2f} ¬± {dados_analise['NOTA_MEDIA'].std():.2f}
- **Taxa de Aprova√ß√£o (‚â•600)**: {dados_analise['APROVADO_600'].mean()*100:.2f}%
- **Taxa de Alta Performance (‚â•700)**: {dados_analise['APROVADO_700'].mean()*100:.2f}%
- **Taxa de Excel√™ncia (‚â•750)**: {dados_analise['ALTA_PERF'].mean()*100:.2f}%

---

## 1Ô∏è‚É£ AN√ÅLISE POR RA√áA/COR

### Disparidades M√°ximas (max - min)
{chr(10).join([f'- **{k}**: {v:.2f} pontos' for k, v in disp_raca.items() if k != 'contagem'])}

### Demographic Parity (Aprova√ß√£o ‚â•600)
- **Diferen√ßa**: {dp_diff:.4f} ({dp_diff*100:.2f} pp)
- **Raz√£o**: {dp_ratio:.4f} {'‚úÖ PASS' if dp_ratio >= 0.80 else '‚ùå FAIL'}

---

## 2Ô∏è‚É£ AN√ÅLISE POR SEXO

### Disparidades M√°ximas
{chr(10).join([f'- **{k}**: {v:.2f} pontos' for k, v in disp_sexo.items() if k != 'contagem'])}

---

## 3Ô∏è‚É£ AN√ÅLISE POR REGI√ÉO

### Disparidades M√°ximas
{chr(10).join([f'- **{k}**: {v:.2f} pontos' for k, v in disp_regiao.items() if k != 'contagem'])}

---

## 4Ô∏è‚É£ AN√ÅLISE INTERSECCIONAL

**Gap M√°ximo (Ra√ßa √ó Sexo)**: {gap_intersec:.2f} pontos

---

## üìä ARQUIVOS GERADOS

### Gr√°ficos (10 visualiza√ß√µes)
1-10. Dashboards, heatmaps, distribui√ß√µes, extremos, correla√ß√µes

### Tabelas (7 arquivos CSV)
1-7. Estat√≠sticas completas por atributo sens√≠vel e interseccionalidade

---

## üéØ CONCLUS√ïES

### Achados Principais

1. **Disparidades Raciais**: Diferen√ßa m√°xima de {disp_raca['m√©dia']:.2f} pontos
2. **Disparidades de G√™nero**: Diferen√ßa de {disp_sexo['m√©dia']:.2f} pontos
3. **Disparidades Regionais**: Diferen√ßa m√°xima de {disp_regiao['m√©dia']:.2f} pontos
4. **Interseccionalidade**: Gap de {gap_intersec:.2f} pontos entre extremos

### Melhorias Implementadas
- ‚úÖ 100% dos dados utilizados (sem amostragem)
- ‚úÖ Processamento otimizado com tipos eficientes
- ‚úÖ 10 visualiza√ß√µes completas (vs 6 anteriores)
- ‚úÖ 9 m√©tricas personalizadas Fairlearn
- ‚úÖ An√°lise de extremos, quartis e decis
- ‚úÖ Organiza√ß√£o de arquivos em subpastas

---

**C√≥digo-fonte**: `analise_fairness_completa.py`  
**Tempo de execu√ß√£o**: ~{(datetime.now() - start_time).total_seconds()/60:.1f} minutos
""")

print("‚úÖ RELATORIO_COMPLETO.md gerado")

# ============================================================================
# FINALIZA√á√ÉO
# ============================================================================

end_time = datetime.now()
elapsed = (end_time - start_time).total_seconds()

print("\n" + "="*100)
print("‚úÖ AN√ÅLISE COMPLETA CONCLU√çDA COM SUCESSO!")
print("="*100)
print(f"T√©rmino: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
print(f"Tempo total: {elapsed/60:.1f} minutos ({elapsed:.0f} segundos)")
print(f"\nüìÅ Resultados salvos em:")
print(f"   - Gr√°ficos: {PATHS['graficos']}/ (10 visualiza√ß√µes)")
print(f"   - Tabelas: {PATHS['tabelas']}/ (7 arquivos CSV)")
print(f"   - Relat√≥rio: {PATHS['reports']}/RELATORIO_COMPLETO.md")
print("\nüí° 100% dos dados utilizados | 0% de amostragem | Performance otimizada")
print("="*100)
